{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">MNIST Dataset Exploration</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the MNIST dataset, a classic dataset of handwritten digits that is commonly used for image classification tasks. We'll look at the dataset properties, visualize examples, and prepare the data for neural network training.\n",
    "\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits (0-9), split into 60,000 training images and 10,000 test images. Each image is 28x28 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set up our environment by importing the necessary libraries and loading the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Set up matplotlib for better visualizations\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorFlow/Keras to download and load the MNIST dataset. This dataset is split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the dataset in more detail to understand its properties and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST images are 28x28 grayscale images, with pixel values ranging from 0 to 255. Let's look at the data types and value ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check data types and value ranges\n",
    "print(f\"Data type: {X_train.dtype}\")\n",
    "print(f\"Min pixel value: {X_train.min()}\")\n",
    "print(f\"Max pixel value: {X_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 10 classes (digits 0-9). Let's examine the distribution of these classes in both the training and test sets to ensure they're balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Count and plot the distribution of digits in the training set\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set distribution\n",
    "ax1.bar(unique_train, counts_train, color='skyblue')\n",
    "ax1.set_title('Training Set Class Distribution')\n",
    "ax1.set_xlabel('Digit')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticks(range(10))\n",
    "\n",
    "# Test set distribution\n",
    "ax2.bar(unique_test, counts_test, color='salmon')\n",
    "ax2.set_title('Test Set Class Distribution')\n",
    "ax2.set_xlabel('Digit')\n",
    "ax2.set_xticks(range(10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the exact counts\n",
    "print(\"Training set distribution:\")\n",
    "for digit, count in zip(unique_train, counts_train):\n",
    "    print(f\"Digit {digit}: {count} samples\")\n",
    "\n",
    "print(\"\\nTest set distribution:\")\n",
    "for digit, count in zip(unique_test, counts_test):\n",
    "    print(f\"Digit {digit}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Visualizing Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some sample images from the dataset to get a better understanding of what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to display random samples\n",
    "def display_digit_samples(X, y, samples_per_digit=5):\n",
    "    \"\"\"Display random samples of each digit.\"\"\"\n",
    "    fig, axes = plt.subplots(10, samples_per_digit, figsize=(12, 14))\n",
    "    fig.suptitle('Random Samples of MNIST Digits', fontsize=16)\n",
    "    \n",
    "    for digit in range(10):\n",
    "        # Find all images of this digit\n",
    "        digit_indices = np.where(y == digit)[0]\n",
    "        \n",
    "        # Select random images of this digit\n",
    "        selected_indices = np.random.choice(digit_indices, samples_per_digit, replace=False)\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            ax = axes[digit, i]\n",
    "            ax.imshow(X[idx], cmap='gray')\n",
    "            ax.set_title(f\"Digit: {digit}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.show()\n",
    "\n",
    "# Display 5 random samples of each digit\n",
    "display_digit_samples(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Pixel Intensity Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the distribution of pixel intensities across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of pixel intensities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Calculate the average pixel intensity for each image\n",
    "avg_pixel_intensity = np.mean(X_train, axis=(1, 2))\n",
    "\n",
    "plt.hist(avg_pixel_intensity, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Average Pixel Intensities')\n",
    "plt.xlabel('Average Pixel Intensity')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate statistics\n",
    "print(f\"Mean pixel intensity: {np.mean(X_train):.2f}\")\n",
    "print(f\"Median pixel intensity: {np.median(X_train):.2f}\")\n",
    "print(f\"Standard deviation of pixel intensities: {np.std(X_train):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Pixel Intensity Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a heatmap showing the average pixel intensity across all training images. This will help us understand which parts of the images are most commonly used for writing digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the average image across all training samples\n",
    "avg_image = np.mean(X_train, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(avg_image, cmap='hot')\n",
    "plt.colorbar(label='Average Pixel Intensity')\n",
    "plt.title('Average Pixel Intensity Across All Training Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. Digit-Specific Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the average image for each digit to see patterns specific to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate average image for each digit\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for digit in range(10):\n",
    "    # Find all images of this digit\n",
    "    digit_indices = np.where(y_train == digit)[0]\n",
    "    digit_images = X_train[digit_indices]\n",
    "    \n",
    "    # Calculate the average image for this digit\n",
    "    avg_digit_image = np.mean(digit_images, axis=0)\n",
    "    \n",
    "    plt.subplot(2, 5, digit + 1)\n",
    "    plt.imshow(avg_digit_image, cmap='viridis')\n",
    "    plt.title(f'Average of Digit {digit}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the dataset for model training, we need to preprocess the data. This typically involves normalization and reshaping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks usually perform better when the input data is normalized. Let's normalize the pixel values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to range [0, 1]\n",
    "X_train_norm = X_train.astype('float32') / 255.0\n",
    "X_test_norm = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Check the new data ranges\n",
    "print(f\"Normalized training data - Min: {X_train_norm.min()}, Max: {X_train_norm.max()}\")\n",
    "print(f\"Normalized test data - Min: {X_test_norm.min()}, Max: {X_test_norm.max()}\")\n",
    "\n",
    "# Visualize a sample before and after normalization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sample_idx = np.random.randint(0, X_train.shape[0])\n",
    "ax1.imshow(X_train[sample_idx], cmap='gray')\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(X_train_norm[sample_idx], cmap='gray')\n",
    "ax2.set_title('Normalized Image')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Data Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a standard neural network (as opposed to a convolutional neural network), we need to flatten the 2D images into 1D vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape data for the model (flattening the images)\n",
    "X_train_flattened = X_train_norm.reshape(X_train_norm.shape[0], -1)\n",
    "X_test_flattened = X_test_norm.reshape(X_test_norm.shape[0], -1)\n",
    "\n",
    "print(f\"Original training data shape: {X_train_norm.shape}\")\n",
    "print(f\"Flattened training data shape: {X_train_flattened.shape}\")\n",
    "print(f\"Original test data shape: {X_test_norm.shape}\")\n",
    "print(f\"Flattened test data shape: {X_test_flattened.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Extraction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, let's extract some simple features from our images and analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract basic features from images\n",
    "def extract_features(images):\n",
    "    \"\"\"Extract basic statistical features from images.\"\"\"\n",
    "    features = []\n",
    "    for img in images:\n",
    "        # Calculate basic statistics\n",
    "        mean_px = np.mean(img)\n",
    "        std_px = np.std(img)\n",
    "        max_px = np.max(img)\n",
    "        min_px = np.min(img)\n",
    "        \n",
    "        # Calculate center of mass\n",
    "        indices = np.indices(img.shape)\n",
    "        y_indices, x_indices = indices[0], indices[1]\n",
    "        total = np.sum(img)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if total == 0:\n",
    "            cx, cy = img.shape[1]//2, img.shape[0]//2\n",
    "        else:\n",
    "            cx = np.sum(x_indices * img) / total\n",
    "            cy = np.sum(y_indices * img) / total\n",
    "        \n",
    "        features.append({\n",
    "            'mean': mean_px,\n",
    "            'std': std_px,\n",
    "            'max': max_px,\n",
    "            'min': min_px,\n",
    "            'center_x': cx,\n",
    "            'center_y': cy\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Extract features from a subset of the training data for demonstration\n",
    "sample_indices = np.random.choice(range(X_train.shape[0]), 5000, replace=False)\n",
    "X_sample = X_train_norm[sample_indices]\n",
    "y_sample = y_train[sample_indices]\n",
    "\n",
    "# Extract features\n",
    "features_df = extract_features(X_sample)\n",
    "features_df['digit'] = y_sample\n",
    "\n",
    "# Display the first few rows of the features dataframe\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore correlations between our extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a correlation matrix for our features\n",
    "corr_matrix = features_df.drop('digit', axis=1).corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Feature Distribution by Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how these features vary across different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature distributions by digit\n",
    "feature_names = ['mean', 'std', 'center_x', 'center_y']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    sns.boxplot(x='digit', y=feature, data=features_df, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature.capitalize()} Distribution by Digit')\n",
    "    axes[i].set_xlabel('Digit')\n",
    "    axes[i].set_ylabel(feature.capitalize())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Feature Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create scatter plots to visualize relationships between features and see if they help separate different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create scatter plots with different color for each digit\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(\n",
    "    features_df['center_x'], \n",
    "    features_df['center_y'], \n",
    "    c=features_df['digit'], \n",
    "    cmap='tab10', \n",
    "    alpha=0.6, \n",
    "    s=50\n",
    ")\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.title('Center of Mass Coordinates by Digit')\n",
    "plt.xlabel('Center X')\n",
    "plt.ylabel('Center Y')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Dimensionality Reduction for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply dimensionality reduction to visualize our high-dimensional data (784 dimensions after flattening) in 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# For demonstration, let's use a smaller subset \n",
    "sample_size = 2000\n",
    "indices = np.random.choice(range(X_train_norm.shape[0]), sample_size, replace=False)\n",
    "X_subset = X_train_flattened[indices]\n",
    "y_subset = y_train[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a technique for dimensionality reduction that finds the directions of maximum variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_subset)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_subset, cmap='tab10', alpha=0.7, s=50)\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.title('PCA Visualization of MNIST Digits')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. t-SNE Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE is a technique for dimensionality reduction that is particularly well suited for visualizing high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply t-SNE (this may take a while to run)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_subset)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_subset, cmap='tab10', alpha=0.7, s=50)\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.title('t-SNE Visualization of MNIST Digits')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we've explored the MNIST dataset of handwritten digits. We've:\n",
    "\n",
    "1. Loaded and examined the structure of the dataset\n",
    "2. Visualized sample images and class distributions\n",
    "3. Analyzed pixel intensity distributions and patterns\n",
    "4. Preprocessed the data through normalization and reshaping\n",
    "5. Extracted and analyzed basic features\n",
    "6. Visualized the high-dimensional data using dimensionality reduction techniques\n",
    "\n",
    "This exploration has given us insights into the characteristics of the MNIST dataset, which will be valuable for building and training models for digit recognition.\n",
    "\n",
    "The next steps would be to build, train, and evaluate machine learning models using this preprocessed data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
